//
//  SYAVCaptureVideoPreviewLayer.swift
//  SYQRCodeDemoSwift
//
//  Created by ree.sun on 16-9-6.
//  Copyright © Ree Sun <ree.sun.cn@hotmail.com || 1507602555@qq.com>
//

import AVFoundation

class SYAVCaptureVideoPreviewLayer {
    private var captureDevice : AVCaptureDevice?
    private var input : AVCaptureDeviceInput?
    private var output : AVCaptureMetadataOutput?
    
    func loadSYAVCaptureVideoPreviewLayer (session: AVCaptureSession!, frame: CGRect, rectOfInterest: CGRect, device: AVCaptureDevice, metadataObjectsDelegate: AVCaptureMetadataOutputObjectsDelegate)->AVCaptureVideoPreviewLayer! {
        captureDevice = device
        
        for capDevice in AVCaptureDevice.devicesWithMediaType(AVMediaTypeVideo) {
            if (capDevice.position == AVCaptureDevicePosition.Back) {
                captureDevice = capDevice as? AVCaptureDevice
            }
        }
        
        if (captureDevice == nil) {
            return nil
        }
        
        if (captureDevice!.hasTorch) {
            alert("当前设备没有闪光灯",msg: nil)
        }
        
        let mSession = AVCaptureSession.init()
        
        //设置检测质量，质量越高扫描越精确，默认AVCaptureSessionPresetHigh
        if captureDevice!.supportsAVCaptureSessionPreset(AVCaptureSessionPreset1920x1080) {
            if mSession.canSetSessionPreset(AVCaptureSessionPreset1920x1080) {
                mSession.sessionPreset = AVCaptureSessionPreset1920x1080
            }
        }
        else if captureDevice!.supportsAVCaptureSessionPreset(AVCaptureSessionPreset1280x720) {
            if mSession.canSetSessionPreset(AVCaptureSessionPreset1280x720) {
                mSession.sessionPreset = AVCaptureSessionPreset1280x720
            }
        }
        
        do {
            input = try AVCaptureDeviceInput(device: captureDevice)
        }
        catch let error as NSError {
            SYLog(error.debugDescription)
        }
        
        if (input == nil) {
            return nil
        }
        mSession.addInput(input)
        
        output = AVCaptureMetadataOutput.init()
        output!.setMetadataObjectsDelegate(metadataObjectsDelegate, queue: dispatch_get_main_queue())
        output!.rectOfInterest = rectOfInterest
        
        if mSession.canAddOutput(output) {
            mSession.addOutput(output)
        }
        else {
            return nil
        }
        
        var availableQRCodeType : Bool = false
        
        for availableType : AnyObject in output!.availableMetadataObjectTypes {
            if (availableType is String) {
                if availableType.lowercaseString.containsString("qrcode") {
                    availableQRCodeType = true
                    SYLog(availableType)
                    
                    break
                }
            }
        }
        
        if availableQRCodeType {
            output!.metadataObjectTypes = [AVMetadataObjectTypeQRCode]
        }
        else {
            return nil
        }
        
        let qrVideoPreviewLayer = AVCaptureVideoPreviewLayer.init(session: mSession)
        qrVideoPreviewLayer.videoGravity = AVLayerVideoGravityResizeAspectFill
        qrVideoPreviewLayer.frame = CGRectMake(0, 0, kSCREEN_WIDTH, kSCREEN_HEIGHT)
        
        return qrVideoPreviewLayer
    }
    
    required init?(coder aDecoder: NSCoder) {
        fatalError("init(coder:) has not been implemented")
    }
}
